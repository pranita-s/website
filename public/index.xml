<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pranita Sharma on Pranita Sharma</title>
    <link>https://pranita-s.github.io/</link>
    <description>Recent content in Pranita Sharma on Pranita Sharma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Example Talk</title>
      <link>https://pranita-s.github.io/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InfraGraf</title>
      <link>https://pranita-s.github.io/project/infragraf/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/infragraf/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I was part of this project during my tenure at Mphasis NEXT Labs as an Intern and Software Engineer.&lt;/li&gt;
&lt;li&gt;InfraGraf® is a Big Data complex event processing engine which enables enterprises to innovate and make strategic decisions regarding their technology infrastructure through actionable insights by correlation and causation analysis structured and unstructured data. It models enterprise technology infrastructure as complex systems consisting of interconnected servers, network devices, internet of things, industrial equipment etc. The powerful machine learning and graph theory based algorithms built into the platform identifies and predicts stand-alone as well as chain of events and incidents which could be related to system warnings, failures, outages, performance, availability and sub-optimal performances.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Leveraging power of Apache Spark Framework -

&lt;ul&gt;
&lt;li&gt;One of the data cleaning algorithms was taking more time than expected and an optimized approach for the same was crucial. I implemented the algorithm using Apache Spark in R programming language taking advantage of its distributed and parallel execution and robust implementation.&lt;/li&gt;
&lt;li&gt;For execution on cluster mode, I used AWS EC2 instances and S3 for storage. I also wrote python script for automating the process of cluster creation, code execution and cluster termination.&lt;/li&gt;
&lt;li&gt;It resulted in the decrease of the run time by 20 folds and was part of the product deployment.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Pattern Extraction from sequence data -

&lt;ul&gt;
&lt;li&gt;Assigned to a team of two.&lt;/li&gt;
&lt;li&gt;This is sub-project of the InfraGraf product. It is aimed at extracting all common patterns among given set event sequences with a minimum support and confidence. A common pattern is defined as a sequence which is subsequence among a defined minimum number of event sequences. Random walk based automata algorithm is built in C for this purpose. This algorithm is tested to give accurate results and implemented in real industrial applications.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Multi-server Architecture using Raspberry Pi</title>
      <link>https://pranita-s.github.io/project/raspberry/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/raspberry/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This was my BE project. I was part of team of four.&lt;/li&gt;
&lt;li&gt;There has been an upsurge observed in the number of small scale and/or home-based businesses. This has been fueled by the internet which makes it very easy to set up one and offer services from the comfort of one’s home, accompanied by the reduction in costs of hardware devices in recent times. However, there are a myriad of networking needs of such offices in order to function smoothly, and most of them are expensive. Some of the most commonly needed ones are an always online file server, an intra-organization email server, a web server and a virtual private network service to stay secure online. We look at a way to cater to these networking needs by providing a solution which is cost effective and involves very low maintenance.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Our Solution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To propose a fulfillment of the above requirements, we used Raspberry Pi. It is a mini computer which can be configured as Web Server, File Server, Email server and VPN at the same time. Being a cheaper alternative and having diverse capabailities, it posed as a great solution.&lt;/li&gt;
&lt;li&gt;We carried out its performace testing in the Central Computer Lab of our college with more than 150 students using the hosted servers at the same time.&lt;/li&gt;
&lt;li&gt;More details can be seen at &lt;a href=&#34;https://drive.google.com/file/d/1BiNaEVf0Hmayupoy5CkdALoDRIPvuvL8/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://drive.google.com/file/d/1BiNaEVf0Hmayupoy5CkdALoDRIPvuvL8/view?usp=sharing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Particle Swarm Optimization</title>
      <link>https://pranita-s.github.io/project/pso/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/pso/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The goal was to exibit the power of PSO with respect to DE as a tuner for SVM. For this comparison, we (a team of three) referred the paper &amp;ldquo;Easy over hard - A Case Study on Deep Learning&amp;rdquo; for the problem statement, data and performance metrics. DE has crossover and mutation functions for its implementation. We chose PSO for comparison as it has simpler implementation which revolves around the two update equations for velocity and position of particle. We wrote the code for PSO from scratch in Python.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;After testing PSO, we found that its performance metrics are at par with those of DE. But the time it takes for convergence is more, hence it is slightly slower than DE. It can be concluded that PSO can be used instead of DE, depending on the usecase and the important factors.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I contributed in the implementation of PSO algorithm in Python.&lt;/li&gt;
&lt;li&gt;Presentation for the same can be seen at - &lt;a href=&#34;https://docs.google.com/presentation/d/1FCd6igOw26W61A8BTVw7EHkDMXfhQ50d6YtcpuwGTMc/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://docs.google.com/presentation/d/1FCd6igOw26W61A8BTVw7EHkDMXfhQ50d6YtcpuwGTMc/edit?usp=sharing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Search into Conversation</title>
      <link>https://pranita-s.github.io/project/alexa/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/alexa/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Conversational user interfaces are becoming increasingly used for a variety of research needs.
Some are voice-activated (such as Alexa, Siri, and Google Now), but many are text-oriented chatbots appearing as assistants in the context of a larger application. Text chatbots are being considered for providing help in using our products, but also for improving the legal research experience
Given a set of case law and judge data, answer research questions using a text-oriented, conversational interface.
For instance, if a user asks &amp;ldquo;List cases for Judge Lucy Koh&amp;rdquo;, the system would respond with a list of cases where Judge Koh is listed as a presiding judge.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Test Cases&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;U: List cases handled by Judge ADAMS&lt;/li&gt;
&lt;li&gt;B: THERE ARE 6 JUDGES with Llast name ADAMS and 2 JUDGES with FIRST NAME&lt;/li&gt;
&lt;li&gt;U: Last name ADAMS&lt;/li&gt;
&lt;li&gt;B: There are only 2 JUDGES with last name ADAMS who are currently on service with first name Henry Lee in Florida and John R in state of OHIO.&lt;/li&gt;
&lt;li&gt;U: The one in state of OHIO&lt;/li&gt;
&lt;li&gt;B: There were 0 cases handled by the judge&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Team&amp;rsquo;s Solution&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We trained DialogFlow with the provided data and then integrated it with Amazon Alexa as a medium of conversation. To accomplish this we used DialogFlow&amp;rsquo;s Alexa Exporter and Amazon Developer Dashboard. After training DialogFlow with the data, we generated Alexa compatible files and then used these files to create a new skill for Alexa.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I trained DialogFlow with help of the data by creating appropriate intents, entities and actions.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Solving Kinematics Word Problem</title>
      <link>https://pranita-s.github.io/project/rnn/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/rnn/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem Description&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Machine is fed with a Kinematics word problem. It has to parse and understand the problem, and decide which equation will be required to solve the problem from the three equations-

&lt;ul&gt;
&lt;li&gt;s = u + a*t&lt;/li&gt;
&lt;li&gt;v*v = u*u + 2*a*s&lt;/li&gt;
&lt;li&gt;s = u*t + 0.5*a*t*t&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;To achieve this, machine has to identify given entites such as velocity, displacement and time and also identify which entity has to be computed.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Existing related research papers concentrate on creating a question template to fit in the given entities and compute the missing one. But this prohibits the question solving capability of the machine to only free fall examples. Hence, I used RNN with LSTM network to train the machine with the questions and the label being the equation to solve it. I used NLP to make the understanding flexible as the machine has to identify details such as &amp;ldquo;at rest&amp;rdquo;,&amp;ldquo;initial velocity&amp;rdquo;,&amp;ldquo;final velocity&amp;rdquo;,&amp;ldquo;starting from rest&amp;rdquo; and also entites with different measuring  units such as metres per second, kilometers per hour etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recognition&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;I presented this work at Woman Who Code Conference held in Bangalore,India in March 2017 as a lightening talk speaker.&lt;/li&gt;
&lt;li&gt;More details about the work can be seen at &lt;a href=&#34;https://drive.google.com/file/d/1eWJSIztqPYhv__SGZO6onDPzCbP_i8Qb/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;https://drive.google.com/file/d/1eWJSIztqPYhv__SGZO6onDPzCbP_i8Qb/view?usp=sharing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Summarization of Document</title>
      <link>https://pranita-s.github.io/project/semantic/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/project/semantic/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I was part of the team during my tenure at Mphasis NEXT Labs as a Software Engineer.&lt;/li&gt;
&lt;li&gt;This project is aimed to summarize grammatically written English document by build a queriable directed graph based on semantics and context (i.e. Event and Action). The query on graph can retrieve information about action and its effect, and entity and its role. We adopted various NLP and text mining methodologies to build the graph and stored the graph in Neo4j for effective information retrieval.&lt;/li&gt;
&lt;li&gt;This project involved usage of R and Python programming language, CoreNLP package for finding co-references among sentences, tokenization and POS tagging, Senna framework for Semantic Role Labelling, Semafor for frame-semantic parsing and Neo4j framework for graph querying.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;My Role&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I implemented co-reference relationship builder using CoreNLP (which internally uses Stanford CoreNLP framework) for replacement of pronouns with their respective nouns.&lt;/li&gt;
&lt;li&gt;I translated retrieved relationship between prominent nouns and verbs from the document pre-processing to Neo4j graph&lt;/li&gt;
&lt;li&gt;(Team of two) We created a GUI in RShiny for a prototype demonstration&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Academic: the website designer for Hugo</title>
      <link>https://pranita-s.github.io/post/getting-started/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0530</pubDate>
      
      <guid>https://pranita-s.github.io/post/getting-started/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Person Re-Identification System For Mobile Devices</title>
      <link>https://pranita-s.github.io/publication/person-re-identification/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/publication/person-re-identification/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mobile visual clothing search</title>
      <link>https://pranita-s.github.io/publication/clothing-search/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/publication/clothing-search/</guid>
      <description>&lt;p&gt;More detail can easily be written here using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pranita-s.github.io/blog/getting_started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pranita-s.github.io/blog/getting_started/</guid>
      <description>&lt;p&gt;+++ title = &amp;ldquo;Academic: the website designer for Hugo&amp;rdquo;&lt;/p&gt;

&lt;p&gt;date = 2016-04-20T00:00:00 lastmod = 2018-01-13T00:00:00 draft = false&lt;/p&gt;

&lt;p&gt;tags = [&amp;ldquo;academic&amp;rdquo;] summary = &amp;ldquo;Create a beautifully simple website or blog in under 10 minutes.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[header] image = &amp;ldquo;headers/getting-started.png&amp;rdquo; caption = &amp;ldquo;Image credit: Academic&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-default.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-default.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Default&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-ocean.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-ocean.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Ocean&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Dark&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-forest.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-forest.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Default&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-coffee-playfair.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-coffee-playfair.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;Coffee theme with Playfair font&amp;rdquo;&lt;/p&gt;

&lt;p&gt;[[gallery_item]] album = &amp;ldquo;1&amp;rdquo; image = &amp;ldquo;&lt;a href=&#34;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-1950s.png&amp;quot;&#34; target=&#34;_blank&#34;&gt;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-1950s.png&amp;quot;&lt;/a&gt; caption = &amp;ldquo;1950s&amp;rdquo; +++&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
